{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading and saving data\n",
    "import pandas as pd \n",
    "\n",
    "# Computations\n",
    "import numpy as np \n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf \n",
    "\n",
    "# Keras API \n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is split into two parts in a single file: dataset1 and dataset2.\n",
    "    \n",
    "Which data is which can be identified from the column **DatasetID**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('data/multitasklearnig_task.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (1000030, 10)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of the dataset: {d.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DatasetID    x1    x2    x3    x4    x5    x6     z   y1  y2\n",
      "0          1 -1.84 -4.66  2.13 -1.32 -5.86 -4.69  2.89  0.0 NaN\n",
      "1          1  1.31  0.16  2.94 -0.88  0.15 -3.69  1.25  1.0 NaN\n",
      "2          1  0.60  4.23 -0.10  0.52  3.04 -0.23 -3.00  1.0 NaN\n",
      "3          1  1.94  1.68  0.15 -3.16  0.12 -3.80  8.14  1.0 NaN\n",
      "4          1  2.95  0.25  0.24 -0.47  3.10  0.69 -0.53  0.0 NaN\n"
     ]
    }
   ],
   "source": [
    "print(d.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DatasetID    x1    x2    x3    x4    x5    x6   z  y1         y2\n",
      "1000025          2 -3.28 -1.20  0.50 -0.43 -2.13 -1.62 NaN NaN -19.905467\n",
      "1000026          2  2.41  5.34 -3.96 -0.62  3.90 -4.47 NaN NaN   3.440164\n",
      "1000027          2  2.74  5.80 -4.03 -0.82  6.98  4.53 NaN NaN  17.879392\n",
      "1000028          2 -0.79 -4.31  3.73  0.83  0.23 -1.59 NaN NaN   0.764875\n",
      "1000029          2  5.15  2.43 -1.69  1.46  3.36 -0.63 NaN NaN  19.181821\n"
     ]
    }
   ],
   "source": [
    "print(d.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of observations for each dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetID\n",
      "1         30\n",
      "2    1000000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(d.groupby('DatasetID').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first data set contains 30 rows while the second one contains 1 million rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting the dataset into two subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first data set target variable is binary - 1 or 0. Thus the objective here is to model a probability given the $X$ matrix: \n",
    "\n",
    "$$ p(Y | X, Z) $$\n",
    "\n",
    "The second one's target variable is continues so the problem is a regression problem: \n",
    "\n",
    "$$ E[Y | X] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subseting\n",
    "d1 = d[d['DatasetID']==1]\n",
    "d2 = d[d['DatasetID']==2]\n",
    "\n",
    "# Reseting the indexes\n",
    "d1.reset_index(inplace=True, drop=True)\n",
    "d2.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the matrices $X_{1}$, $Y_{1}$ for the logistic problem and $X_{2}$, $Y_{2}$ for the regression problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features\n",
    "features_x = ['x1', 'x2', 'x3', 'x4', 'x5', 'x6']\n",
    "features_z = ['z']\n",
    "\n",
    "# 'Probabalistic' dataset\n",
    "X1, Z1, Y1 = d1[features], d1[features_z], d1['y1']\n",
    "\n",
    "# 'Continues' dataset\n",
    "X2, Y2 = d2[features], d2['y2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the datasets have dependencies from one another in their data generating process.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ p(Y_{1}| X_{1}, Z) = \\dfrac{1}{1 - e^{-(\\beta_{1}X_{1} + \\beta_{2}Z})} \\in (0, 1) $$ \n",
    "\n",
    "$$ E[Y_{2}|X_{2}] = \\beta_{3} X_{2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\beta_{1} = \\alpha \\beta_{3} $$ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
